# Sport Agent ä¼ä¸šçº§å®æ–½è·¯çº¿å›¾

**æ–‡æ¡£çŠ¶æ€**: Agent Phase 1 è§„åˆ’ï¼ˆWeek 1-2ï¼‰
**æœ€åæ›´æ–°**: 2024-11-21
**è´Ÿè´£äºº**: Agent Team (ä½ )

---

## ğŸ“Š å½“å‰çŠ¶æ€å¿«ç…§

### âœ… å·²å®Œæˆ (Week 0)
- [x] Planner v1.2: 100% é€šè¿‡ Golden Dataset
- [x] 12 ç§å·¥å…·æ¥å£å®Œæ•´å®šä¹‰
- [x] API æ¡†æ¶ä¸è·¯ç”±
- [x] å·¥å…·æ³¨å†Œè¡¨é…ç½®

### ğŸš€ åˆšå®Œæˆ (Today)
- [x] ParameterResolver - å‚æ•°è§£æä¸ç»‘å®šç³»ç»Ÿ
- [x] Executor - å·¥å…·æ‰§è¡Œæ¡†æ¶
- [x] MockToolResponses - å®Œæ•´ Mock æ•°æ®åº“ (13 ç§å·¥å…·)
- [x] AgentOrchestrator - ç¼–æ’å™¨æ•´åˆ

### â³ ä¸‹ä¸€æ­¥ (Week 1-2)
- [ ] é›†æˆåˆ° API æœåŠ¡
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•
- [ ] æ€§èƒ½åŸºçº¿å»ºç«‹
- [ ] æ–‡æ¡£ä¸æ¼”ç¤º

---

## ğŸ¯ Phase 1: æ ¸å¿ƒæ‰§è¡Œå±‚ (Week 1-2)

### ä»»åŠ¡ 1.1: å‚æ•°è§£æä¸ç»‘å®šç³»ç»Ÿ âœ… å®Œæˆ

**æ–‡ä»¶**: `src/agent/core/parameter_resolver.py` (220 è¡Œ)

**æ ¸å¿ƒåŠŸèƒ½**:
```python
# è¾“å…¥
step = "PredictionTool(match_id=$match_id, phase='T-24h')"

# è§£æ
parsed = resolver.parse_step(step)
# è¾“å‡º: ParsedToolStep(
#   tool_name="PredictionTool",
#   raw_params={"match_id": "$match_id", "phase": "'T-24h'"},
# )

# å¡«å……å ä½ç¬¦
context = {"match_id": "man-utd-001"}
resolved = resolver.resolve_placeholders(parsed, context)
# è¾“å‡º: params = {"match_id": "man-utd-001", "phase": "T-24h"}
```

**å…³é”®èƒ½åŠ›**:
- âœ… å·¥å…·æ­¥éª¤å­—ç¬¦ä¸²æ­£åˆ™è§£æ
- âœ… å‚æ•°æå–ä¸åˆ†å‰²
- âœ… å ä½ç¬¦è¯†åˆ«ä¸ç»‘å®š
- âœ… ç±»å‹è½¬æ¢ (å­—ç¬¦ä¸²/æ•°å­—/å¸ƒå°”/æ•°ç»„)
- âœ… é”™è¯¯å¤„ç†

**ä»£ç ç¤ºä¾‹**:
```python
from src.agent.core.parameter_resolver import ParameterResolver

resolver = ParameterResolver()

# 1. è§£æ
parsed = resolver.parse_step("MatchResolverTool(query='Barcelona')")
# ParsedToolStep(tool_name="MatchResolverTool", raw_params={"query": "Barcelona"})

# 2. å¡«å……å ä½ç¬¦
context = {"match_id": "barcelona-001"}
resolved = resolver.resolve_placeholders(parsed, context)
# params = {"query": "Barcelona"}

# 3. æ‰¹é‡å¤„ç†
all_resolved = resolver.resolve_all_steps(plan_steps)
```

---

### ä»»åŠ¡ 1.2: Executor å·¥å…·æ‰§è¡Œæ¡†æ¶ âœ… å®Œæˆ

**æ–‡ä»¶**: `src/agent/core/executor.py` (310 è¡Œ)

**æ ¸å¿ƒåŠŸèƒ½**:
```python
async with Executor(settings) as executor:
    result = await executor.execute_plan(
        plan_steps=[
            "MatchResolverTool(query='Barcelona')",
            "PredictionTool(match_id=$match_id, phase='T-24h')",
        ],
        match_id_hint="barca-001"  # å¯é€‰åˆå§‹åŒ–
    )
```

**å·¥ä½œæµ**:
```
è¾“å…¥: plan_steps
  â†“
å‚æ•°è§£æ (ParameterResolver)
  â†“
éå†æ¯ä¸ªæ­¥éª¤:
  - æŸ¥è¯¢å·¥å…·é…ç½®
  - æ„å»º HTTP è¯·æ±‚
  - å‘é€è¯·æ±‚ (httpx)
  - è§£æå“åº”
  - æ›´æ–°ä¸Šä¸‹æ–‡
  â†“
è¿”å›: execution_summary
```

**å…³é”®ç‰¹æ€§**:
- âœ… å·¥å…·æŸ¥è¯¢ä¸é…ç½®æ˜ å°„
- âœ… HTTP å®¢æˆ·ç«¯ç®¡ç† (httpx AsyncClient)
- âœ… è¯·æ±‚/å“åº”å¤„ç†
- âœ… ä¸Šä¸‹æ–‡ç»´æŠ¤ä¸æ›´æ–°
- âœ… é”™è¯¯å¤„ç†ä¸æ—¥å¿—
- âœ… æ€§èƒ½è¿½è¸ª (latency_ms)

**è®¾è®¡ä¼˜åŠ¿**:
- å¼‚æ­¥æ‰§è¡Œ (asyncio)
- å‚æ•°ä¾èµ–è‡ªåŠ¨å¡«å……
- è¶…æ—¶æ§åˆ¶
- å¤±è´¥æ¢å¤

---

### ä»»åŠ¡ 1.3: Mock å·¥å…·å“åº”åº“ âœ… å®Œæˆ

**æ–‡ä»¶**: `src/agent/tools/mock_responses.py` (650 è¡Œ)

**åŒ…å« 13 ç§å·¥å…·çš„å®Œæ•´ Mock å®ç°**:

| å·¥å…· | å“åº”ç±»å‹ | æ•°æ®é‡ | è¦†ç›–åœºæ™¯ |
|------|---------|--------|---------|
| MatchResolverTool | match_id, teams | 5 å¯¹çƒé˜Ÿ | è¶³çƒã€éè¶³çƒ |
| StatsAnalysisTool | highlights, flags | 4-6 é¡¹ | å¼ºé˜Ÿã€å¼±é˜Ÿã€ä¼¤ç—… |
| HistoricalComparisonTool | h2h_summary, advantage | æ–‡æœ¬ + æµ®ç‚¹ | åŠ¿å‡åŠ›æ•Œã€å•è¾¹å‹å€’ |
| TacticalInsightTool | formations, style | åˆ—è¡¨ + Literal | 5 ç§æˆ˜æœ¯é£æ ¼ |
| LiveFeedTool | possession, events | å®æ—¶æ•°æ® | é¢†å…ˆã€è½åã€å¹³å±€ |
| PostMatchReviewTool | timeline, comparison | é•¿æ–‡æœ¬ | å„ç§ç»“å±€ |
| **PredictionTool** | home/draw/away | æ¦‚ç‡åˆ†å¸ƒ | å†·é—¨ã€çƒ­é—¨ |
| ScorelinePredictorTool | scorelines, probs | top-3 | å¸¸è§æ¯”åˆ† |
| EventPredictorTool | buckets, probs | 3-4 æ¡£ | è¿›çƒã€è§’çƒã€é»„ç‰Œ |
| NewsTool | items, summary | 3 æ¡æ–°é—» | ä¼¤ç—…ã€è½¬ä¼šã€æˆ˜æœ¯ |
| OddsTool | markets, anomalies | 2 å®¶åšå½© | æ­£å¸¸ã€å¼‚å¸¸æ³¢åŠ¨ |
| LLMAugmentorTool | reasoning_chain | CoT æ­¥éª¤ | æ¨ç†é“¾ |
| StrategyTool | recommendation | 3 ç§åå¥½ | ä¿å®ˆã€å‡è¡¡ã€æ¿€è¿› |

**å…³é”®ç‰¹æ€§**:
- âœ… ç¡®å®šæ€§ä¼ªæ•°æ® (åŸºäº hash seed)
- âœ… é«˜åº¦çœŸå®æ€§ (åˆ†å¸ƒç¬¦åˆè¶³çƒæ¯”èµ›)
- âœ… è¦†ç›–å„ç§åœºæ™¯ (æ— ç¼é›†æˆåˆ°æµ‹è¯•)
- âœ… Pydantic Schema éªŒè¯
- âœ… æ˜“äºé€æ­¥æ›¿æ¢ä¸ºçœŸå®æœåŠ¡

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from src.agent.tools.mock_responses import MockToolResponses

mock = MockToolResponses()

# ç¡®å®šæ€§ä¼ªæ•°æ®
pred1 = mock.prediction(match_id="barca-001", phase="T-24h")
pred2 = mock.prediction(match_id="barca-001", phase="T-24h")
# pred1 == pred2 (å®Œå…¨ç›¸åŒï¼Œä¾¿äºè°ƒè¯•)

# ä¸åŒçš„ match_id â†’ ä¸åŒçš„é¢„æµ‹
pred3 = mock.prediction(match_id="real-001", phase="T-24h")
# pred3 != pred1 (å®Œå…¨ä¸åŒ)
```

---

### ä»»åŠ¡ 1.4: Agent ç¼–æ’å™¨ âœ… å®Œæˆ

**æ–‡ä»¶**: `src/agent/orchestrator.py` (280 è¡Œ)

**æ•´åˆ Planner + Executor + Mock**:
```python
orchestrator = AgentOrchestrator(settings)

result = await orchestrator.orchestrate(
    query="å·´è¨ä¸‹ä¸€åœºè°ä¼šèµ¢ï¼Ÿ",
    user_id="user_123",
    preferred_phase="T-24h",
)

# è¾“å‡º:
{
    "query": "å·´è¨ä¸‹ä¸€åœºè°ä¼šèµ¢ï¼Ÿ",
    "plan_steps": [
        "MatchResolverTool(query='...Barcelona...')",
        "PredictionTool(match_id=$match_id, phase='T-24h')",
        ...
    ],
    "execution_result": {
        "tools_executed": ["MatchResolverTool", "PredictionTool"],
        "results": {
            "MatchResolverTool": {...},
            "PredictionTool": {...},
        },
        "total_latency_ms": 250
    },
    "answer": "æˆ‘å·²ç»ä¸ºæ‚¨çš„é—®é¢˜... [è¯¦ç»†åˆ†æ]",
    "status": "success"
}
```

**å·¥ä½œæµ**:
```
ç”¨æˆ·æŸ¥è¯¢
  â†“
Planner.plan_decomposition()
  â†“
Executor.execute_plan() (å½“å‰: Mock)
  â†“
_build_answer() (è‡ªç„¶è¯­è¨€æ•´åˆ)
  â†“
è¿”å›å®Œæ•´å“åº”
```

---

## ğŸ“‹ ä¸‹ä¸€æ­¥: Phase 1 å®Œæˆæ¸…å• (Week 1)

### ä»»åŠ¡ 1.5: é›†æˆåˆ° API æœåŠ¡

**å½“å‰çŠ¶æ€**: AgentService ä»ä½¿ç”¨æ—§çš„ Mock é€»è¾‘

**éœ€è¦åš**:
```python
# æ–‡ä»¶: src/services/api/services/agent.py (æ›´æ–°)

class AgentService:
    def __init__(self, settings: Settings):
        self._settings = settings
        self.orchestrator = AgentOrchestrator(settings)  # æ–°å¢

    async def run_query(self, payload: AgentQuery) -> AgentResponse:
        # ä½¿ç”¨æ–°çš„ Orchestrator
        result = await self.orchestrator.orchestrate(
            query=payload.query,
            user_id=payload.user_id,
            preferred_phase=payload.preferred_phase,
        )

        # è½¬æ¢ä¸º API å“åº”æ ¼å¼
        return AgentResponse(
            answer=result["answer"],
            reasoning=self._extract_reasoning(result),
            plan_steps=result["plan_steps"],
            tool_traces=self._build_traces(result["execution_result"]),
            planner_version="v1.2+executor",
            generated_at=datetime.now(timezone.utc),
        )
```

**å·¥æ—¶**: 2-3 å°æ—¶

---

### ä»»åŠ¡ 1.6: ç«¯åˆ°ç«¯æµ‹è¯•

**åˆ›å»ºæµ‹è¯•æ–‡ä»¶**: `tests/test_agent_e2e.py`

```python
import pytest
from src.services.api.services.agent import AgentService
from src.services.api.schemas.agent import AgentQuery
from src.shared.config import get_settings

@pytest.mark.asyncio
async def test_agent_e2e_basic():
    """æµ‹è¯•: Agent å®Œæ•´æµç¨‹"""
    settings = get_settings()
    service = AgentService(settings)

    payload = AgentQuery(query="å·´è¨ä¸‹ä¸€åœºè°ä¼šèµ¢ï¼Ÿ")
    response = await service.run_query(payload)

    # éªŒè¯å“åº”ç»“æ„
    assert response.answer is not None
    assert len(response.plan_steps) > 0
    assert response.planner_version == "v1.2+executor"

@pytest.mark.asyncio
async def test_agent_multi_tool():
    """æµ‹è¯•: å¤šå·¥å…·åä½œ"""
    settings = get_settings()
    service = AgentService(settings)

    # å¤æ‚æŸ¥è¯¢: éœ€è¦å¤šä¸ªå·¥å…·
    payload = AgentQuery(
        query="å·´é»è¿™æ³¢è¿èƒœèƒ½å¦æŒç»­ï¼Ÿè¯·ç»“åˆèµ›ç¨‹å’Œä½“èƒ½ã€‚"
    )
    response = await service.run_query(payload)

    # éªŒè¯å¤šä¸ªå·¥å…·è¢«è°ƒç”¨
    assert len(response.plan_steps) >= 3
    assert any("Stats" in step for step in response.plan_steps)
    assert any("News" in step for step in response.plan_steps)

@pytest.mark.asyncio
async def test_golden_dataset():
    """å›å½’æµ‹è¯•: Golden Dataset æ‰€æœ‰ 20 ä¸ªç”¨ä¾‹"""
    import json
    settings = get_settings()
    service = AgentService(settings)

    with open("tests/data/golden_dataset.json") as f:
        dataset = json.load(f)

    for case in dataset:
        payload = AgentQuery(query=case["question"])
        response = await service.run_query(payload)

        # éªŒè¯å“åº”æœ‰æ•ˆ
        assert response.answer is not None
        assert len(response.plan_steps) > 0
```

**å·¥æ—¶**: 4-6 å°æ—¶

---

### ä»»åŠ¡ 1.7: æ€§èƒ½åŸºçº¿å»ºç«‹

**åˆ›å»ºæ€§èƒ½æµ‹è¯•**: `tests/test_agent_performance.py`

```python
import asyncio
import time
import pytest
from src.services.api.services.agent import AgentService
from src.services.api.schemas.agent import AgentQuery
from src.shared.config import get_settings

@pytest.mark.asyncio
async def test_agent_latency():
    """æ€§èƒ½åŸºçº¿: å•æ¬¡æŸ¥è¯¢å»¶è¿Ÿ"""
    settings = get_settings()
    service = AgentService(settings)

    queries = [
        "å·´è¨ä¸‹ä¸€åœºè°ä¼šèµ¢ï¼Ÿ",
        "æ›¼è”å’Œåˆ©ç‰©æµ¦æœ€è¿‘5æ¬¡äº¤é”‹è°æ›´å¼ºï¼Ÿ",
        "å·´é»è¿™æ³¢è¿èƒœèƒ½å¦æŒç»­ï¼Ÿ",
    ]

    latencies = []
    for query in queries:
        payload = AgentQuery(query=query)

        start = time.time()
        response = await service.run_query(payload)
        latency = (time.time() - start) * 1000  # ms

        latencies.append(latency)

    print(f"âœ… æ€§èƒ½åŸºçº¿:")
    print(f"   å¹³å‡å»¶è¿Ÿ: {sum(latencies)/len(latencies):.0f} ms")
    print(f"   æœ€å°å»¶è¿Ÿ: {min(latencies):.0f} ms")
    print(f"   æœ€å¤§å»¶è¿Ÿ: {max(latencies):.0f} ms")

    # çº¦æŸ: å•æ¬¡æŸ¥è¯¢ < 1000 ms (å½“å‰ Mock, åº”è¯¥ < 500ms)
    assert sum(latencies) / len(latencies) < 1000

@pytest.mark.asyncio
async def test_concurrent_queries():
    """å‹åŠ›æµ‹è¯•: å¹¶å‘æŸ¥è¯¢"""
    settings = get_settings()
    service = AgentService(settings)

    async def query():
        payload = AgentQuery(query="å·´è¨ä¸‹ä¸€åœºè°ä¼šèµ¢ï¼Ÿ")
        return await service.run_query(payload)

    # 10 ä¸ªå¹¶å‘æŸ¥è¯¢
    start = time.time()
    results = await asyncio.gather(*[query() for _ in range(10)])
    total_time = time.time() - start

    print(f"âœ… å¹¶å‘æ€§èƒ½:")
    print(f"   10 ä¸ªæŸ¥è¯¢è€—æ—¶: {total_time*1000:.0f} ms")
    print(f"   å¹³å‡æ¯ä¸ª: {total_time*1000/10:.0f} ms")

    assert len(results) == 10
    assert all(r.answer is not None for r in results)
```

**å·¥æ—¶**: 3-4 å°æ—¶

---

### ä»»åŠ¡ 1.8: æ–‡æ¡£ä¸æ¼”ç¤º

**æ›´æ–°æ–‡æ¡£**:
- `docs/agent-implementation-roadmap.md` (æœ¬æ–‡æ¡£)
- `docs/agent-api-usage.md` (API ä½¿ç”¨æŒ‡å—)
- `src/agent/orchestrator.py` (ä»£ç æ³¨é‡Š)

**åˆ›å»ºæ¼”ç¤ºè„šæœ¬**: `demo_agent.py`

```python
#!/usr/bin/env python3
"""Agent æ¼”ç¤ºè„šæœ¬"""
import asyncio
from src.services.api.services.agent import AgentService
from src.services.api.schemas.agent import AgentQuery
from src.shared.config import get_settings

async def main():
    settings = get_settings()
    service = AgentService(settings)

    # æ¼”ç¤º 1: ç®€å•é¢„æµ‹
    print("\n[æ¼”ç¤º 1] ç®€å•é¢„æµ‹")
    print("=" * 50)
    payload = AgentQuery(query="å·´è¨ä¸‹ä¸€åœºè°ä¼šèµ¢ï¼Ÿ")
    response = await service.run_query(payload)
    print(f"ç”¨æˆ·æé—®: {payload.query}")
    print(f"Agent å›ç­”: {response.answer[:200]}...")
    print(f"ä½¿ç”¨å·¥å…·: {response.plan_steps}")

    # æ¼”ç¤º 2: å¤æ‚åˆ†æ
    print("\n[æ¼”ç¤º 2] å¤æ‚åˆ†æ")
    print("=" * 50)
    payload = AgentQuery(
        query="å·´é»è¿™æ³¢è¿èƒœæ˜¯å¦å¯æŒç»­ï¼Ÿè¯·ç»“åˆèµ›ç¨‹å’Œä½“èƒ½ã€‚"
    )
    response = await service.run_query(payload)
    print(f"ç”¨æˆ·æé—®: {payload.query}")
    print(f"Agent å›ç­”: {response.answer[:200]}...")
    print(f"ä½¿ç”¨å·¥å…·æ•°: {len(response.plan_steps)}")

    # æ¼”ç¤º 3: å¤šè½®å¯¹è¯ç¤ºæ„
    print("\n[æ¼”ç¤º 3] å¤šå·¥å…·åä½œ")
    print("=" * 50)
    print(f"ç”¨æˆ·æé—®: é©¬å¾·é‡Œå¾·æ¯”èµ”ç‡æœ‰æ²¡æœ‰å¼‚å¸¸æ³¢åŠ¨ï¼Ÿ")
    payload = AgentQuery(query="é©¬å¾·é‡Œå¾·æ¯”èµ”ç‡æœ‰æ²¡æœ‰å¼‚å¸¸æ³¢åŠ¨ï¼Ÿ")
    response = await service.run_query(payload)
    print(f"ä½¿ç”¨å·¥å…·: {response.plan_steps}")

if __name__ == "__main__":
    asyncio.run(main())
```

**å·¥æ—¶**: 2-3 å°æ—¶

---

## ğŸ¯ Phase 2: ä¼˜åŒ–ä¸æ‰©å±• (Week 2-3)

### å¯é€‰ä»»åŠ¡ 2.1: Multi-Turn å¯¹è¯

**ç›®æ ‡**: æ”¯æŒè¿½é—®ä¸ä¸Šä¸‹æ–‡ä¼ é€’

```python
# API æ”¯æŒå¯¹è¯å†å²
POST /api/v1/agent/query
{
    "conversation_id": "conv_123",  # æ–°å¢
    "query": "ä¸ºä»€ä¹ˆï¼Ÿ",
    "user_id": "user_456"
}

Response:
{
    "answer": "å› ä¸ºä¸»é˜Ÿä¼¤ç—…è¾ƒå¤š...",
    "context": {  # æ–°å¢
        "previous_query": "å·´è¨ä¸‹ä¸€åœºè°ä¼šèµ¢ï¼Ÿ",
        "conversation_history": [...]
    }
}
```

**å®ç°æ–¹æ¡ˆ**:
- Redis å­˜å‚¨å¯¹è¯ context (TTL=1 hour)
- Context Compression (çª—å£è¶…é™æ—¶æ‘˜è¦)
- è‡ªåŠ¨ query è¡¥å…¨

---

### å¯é€‰ä»»åŠ¡ 2.2: LLM é›†æˆ

**ç›®æ ‡**: ç”¨çœŸå® LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€

```python
from openai import AsyncOpenAI

client = AsyncOpenAI(api_key=os.environ["OPENAI_API_KEY"])

response = await client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€åèµ„æ·±è¶³çƒè¯„è®ºå‘˜..."
        },
        {
            "role": "user",
            "content": f"æ ¹æ®ä»¥ä¸‹åˆ†æç»“æœå›ç­”: {tool_outputs}"
        }
    ],
    temperature=0.7,
    max_tokens=500,
)
```

---

### å¯é€‰ä»»åŠ¡ 2.3: ç¼“å­˜ç³»ç»Ÿ

**ç›®æ ‡**: åŠ é€Ÿé‡å¤æŸ¥è¯¢

```python
# Redis ç¼“å­˜ç­–ç•¥
cache_key = f"tool:{tool_name}:{hash(params)}"
cached = await redis.get(cache_key)

if cached:
    return json.loads(cached)  # å‘½ä¸­ç¼“å­˜

# æ‰§è¡Œå·¥å…·
result = await executor.execute_tool(...)

# å†™å…¥ç¼“å­˜ (TTL=5 min)
await redis.setex(cache_key, 300, json.dumps(result))
```

---

## ğŸ“Š äº¤ä»˜æ¸…å•

### Week 1 å®Œæˆæ ‡å‡†
- [x] ParameterResolver å®Œæ•´å®ç°
- [x] Executor æ¡†æ¶å°±ä½
- [x] MockToolResponses 13 ç§å·¥å…·è¦†ç›–
- [x] AgentOrchestrator æ•´åˆ
- [ ] é›†æˆåˆ° AgentService
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•è¦†ç›– (Golden Dataset)
- [ ] æ€§èƒ½åŸºçº¿ç¡®ç«‹ (P50 < 500ms, P99 < 1000ms)
- [ ] API æ–‡æ¡£æ›´æ–°

### æˆåŠŸæŒ‡æ ‡
- **åŠŸèƒ½**: Golden Dataset 100% é€šè¿‡
- **æ€§èƒ½**: å•æ¬¡æŸ¥è¯¢ < 1000ms
- **å¯é æ€§**: å¹¶å‘ 10 ä¸ªæŸ¥è¯¢æ— é”™è¯¯
- **è¦†ç›–**: 13 ç§å·¥å…·å…¨éƒ¨å¯ç”¨

---

## ğŸ”„ ä¸å…¶ä»–æ¨¡å—çš„é›†æˆ

### ä¸ Prediction Service çš„é›†æˆ
```
Agent Query
  â†’ PredictionTool è°ƒç”¨
  â†’ src/services/api/services/prediction.py
  â†’ å½“å‰è¿”å› Mock æ•°æ®
  â†’ æœªæ¥: çœŸå® XGBoost æ¨¡å‹
```

### ä¸ News Service çš„é›†æˆ
```
Agent Query
  â†’ NewsTool è°ƒç”¨
  â†’ src/services/api/services/news.py
  â†’ å½“å‰è¿”å› Mock æ•°æ®
  â†’ æœªæ¥: çœŸå®èµ„è®¯çˆ¬è™« + NLP
```

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

- `docs/agent-design.md` - Agent æ¶æ„è®¾è®¡
- `docs/project-initial-plan.md` - é¡¹ç›®æ•´ä½“è®¡åˆ’
- `config/agent_tools.yaml` - å·¥å…·æ³¨å†Œè¡¨
- `tests/data/golden_dataset.json` - 20 ä¸ªæµ‹è¯•ç”¨ä¾‹

---

## âš¡ å¿«é€Ÿå¯åŠ¨

```bash
# 1. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# 2. è¿è¡Œ Planner å›å½’æµ‹è¯•
python3 evaluate_planner.py --verbose

# 3. å¯åŠ¨ API æœåŠ¡
uvicorn src.services.api.main:app --reload

# 4. åœ¨å¦ä¸€ä¸ªç»ˆç«¯æµ‹è¯•
curl -X POST http://localhost:8080/api/v1/agent/query \
  -H "Content-Type: application/json" \
  -d '{"query": "å·´è¨ä¸‹ä¸€åœºè°ä¼šèµ¢ï¼Ÿ"}'

# 5. æŸ¥çœ‹ Swagger æ–‡æ¡£
# è®¿é—® http://localhost:8080/docs
```

---

## ğŸ’¬ å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆä½¿ç”¨ Mock å·¥å…·ï¼Ÿ
**A**: åœ¨çœŸå®æ•°æ®æºï¼ˆç‰¹å¾ä»“ã€æ¨¡å‹æœåŠ¡ã€èµ„è®¯çˆ¬è™«ï¼‰å°±ä½å‰ï¼ŒMock æä¾›ï¼š
- ä¸è¢«æ•°æ®å»¶è¿Ÿé˜»å¡
- å¿«é€Ÿçš„åŠŸèƒ½éªŒè¯
- æ¸…æ™°çš„å·¥å…·æ¥å£
- é€æ­¥æ›¿æ¢çš„é€šé“

### Q: ä½•æ—¶ç”¨çœŸå®æ•°æ®æ›¿æ¢ Mockï¼Ÿ
**A**: å½“ä»¥ä¸‹æ¨¡å—å®Œæˆæ—¶ï¼š
1. Prediction Service - çœŸå® XGBoost æ¨¡å‹
2. News Service - èµ„è®¯çˆ¬è™«ä¸ NLP
3. Feature Store - çƒé˜Ÿ/çƒå‘˜ç‰¹å¾
4. Entity Resolution - çƒé˜Ÿ/çƒå‘˜æ˜ å°„

### Q: Agent æ€§èƒ½ç“¶é¢ˆåœ¨å“ªï¼Ÿ
**A**: å½“å‰ï¼ˆMockï¼‰: ç½‘ç»œ I/Oï¼ˆExecutorï¼‰
æœªæ¥ï¼ˆçœŸå®ï¼‰: Model inference (PredictionTool), èµ„è®¯æŸ¥è¯¢ (NewsTool)

---

**ä¸‹ä¸€æ­¥**: é€‰æ‹© Phase 1.5 æˆ– Phase 2 ä¸­çš„ä»»åŠ¡å¼€å§‹å®æ–½ï¼
