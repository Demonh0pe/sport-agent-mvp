"""
Airflow DAG: Football Data æ‘„å–ç®¡é“

è°ƒåº¦ç­–ç•¥ï¼š
- æ¯å¤© 03:00 UTC å…¨é‡æ›´æ–°ï¼ˆèµ›åæ•°æ®åŒæ­¥ï¼‰
- æ¯å°æ—¶å¢é‡æ›´æ–°ï¼ˆèµ›ä¸­æ•°æ®åŒæ­¥ï¼‰
- æ¯”èµ›æ—¥å‰ååŠ å¯†é›†ç›‘æ§

ä¾èµ–ï¼š
- PostgreSQL (æ•°æ®åº“)
- Football-data.org API
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.utils.dates import days_ago
import sys
import os

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®ä»£ç 
sys.path.append('/app')  # Docker å®¹å™¨ä¸­çš„é¡¹ç›®è·¯å¾„ï¼Œæœ¬åœ°å¼€å‘æ—¶éœ€è¦è°ƒæ•´

# é»˜è®¤å‚æ•°
default_args = {
    'owner': 'sport-agent-team',
    'depends_on_past': False,
    'email': ['alerts@sport-agent.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
    'execution_timeout': timedelta(minutes=30),
}


def run_data_ingestion(**context):
    """è¿è¡Œæ•°æ®æ‘„å–ä»»åŠ¡"""
    import asyncio
    from src.data_pipeline.ingest_football_data_v2 import FootballDataIngester
    
    ingester = FootballDataIngester()
    
    # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ç­–ç•¥
    task_type = context.get('params', {}).get('task_type', 'incremental')
    
    if task_type == 'full':
        # å…¨é‡æ›´æ–°ï¼šæ‰€æœ‰è”èµ›
        leagues = ["PL", "BL1", "PD", "SA", "FL1", "CL"]
        asyncio.run(ingester.run_full_ingestion(leagues=leagues))
    else:
        # å¢é‡æ›´æ–°ï¼šä»…ä¸»è¦è”èµ›
        leagues = ["PL", "BL1"]  # æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´
        asyncio.run(ingester.run_full_ingestion(leagues=leagues))
    
    # è¿”å›ç»Ÿè®¡ä¿¡æ¯
    return ingester.stats


def validate_data_quality(**context):
    """æ•°æ®è´¨é‡æ£€æŸ¥"""
    import asyncio
    from sqlalchemy import select, func
    from src.infra.db.session import AsyncSessionLocal
    from src.infra.db.models import Match
    
    async def check_quality():
        async with AsyncSessionLocal() as db:
            # æ£€æŸ¥1: ä»Šå¤©æ˜¯å¦æœ‰æ–°æ•°æ®
            today_start = datetime.now().replace(hour=0, minute=0, second=0)
            stmt = select(func.count(Match.match_id)).where(
                Match.created_at >= today_start
            )
            result = await db.execute(stmt)
            today_count = result.scalar()
            
            if today_count == 0:
                raise ValueError("æ•°æ®è´¨é‡å‘Šè­¦: ä»Šæ—¥æ— æ–°å¢æ¯”èµ›æ•°æ®ï¼")
            
            # æ£€æŸ¥2: æ˜¯å¦æœ‰å¼‚å¸¸æ¯”åˆ†
            stmt = select(Match).where(
                Match.status == "FINISHED",
                Match.home_score > 15  # å¼‚å¸¸é«˜åˆ†
            )
            result = await db.execute(stmt)
            anomalies = result.scalars().all()
            
            if anomalies:
                print(f"å‘ç° {len(anomalies)} åœºå¼‚å¸¸æ¯”åˆ†ï¼Œéœ€è¦äººå·¥å®¡æ ¸")
            
            print(f"æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡: ä»Šæ—¥æ–°å¢ {today_count} åœºæ¯”èµ›")
            return {"today_count": today_count, "anomalies": len(anomalies)}
    
    return asyncio.run(check_quality())


def send_summary_notification(**context):
    """å‘é€æ‘˜è¦é€šçŸ¥ï¼ˆå¯é›†æˆ Slack/é’‰é’‰/é‚®ä»¶ï¼‰"""
    task_instance = context['task_instance']
    stats = task_instance.xcom_pull(task_ids='ingest_data')
    quality = task_instance.xcom_pull(task_ids='validate_quality')
    
    message = f"""
    ğŸ“Š Football Data æ‘„å–ä»»åŠ¡å®Œæˆ
    
    âœ… æˆåŠŸå…¥åº“: {stats.get('successfully_ingested', 0)} åœº
    âš ï¸  å®ä½“è§£æå¤±è´¥: {stats.get('failed_resolution', 0)} åœº
    âŒ é”™è¯¯: {stats.get('errors', 0)} åœº
    
    ğŸ“ˆ æ•°æ®è´¨é‡:
    - ä»Šæ—¥æ–°å¢: {quality.get('today_count', 0)} åœº
    - å¼‚å¸¸è®°å½•: {quality.get('anomalies', 0)} åœº
    
    æ‰§è¡Œæ—¶é—´: {context['execution_date']}
    """
    
    print(message)
    # TODO: é›†æˆå®é™…é€šçŸ¥æ¸ é“
    # slack_webhook(message)
    # dingtalk_webhook(message)


# ========================
# DAG 1: æ¯æ—¥å…¨é‡æ›´æ–°
# ========================
with DAG(
    'football_data_daily_full_sync',
    default_args=default_args,
    description='æ¯æ—¥å…¨é‡åŒæ­¥ Football Data',
    schedule_interval='0 3 * * *',  # æ¯å¤© 03:00 UTC
    start_date=days_ago(1),
    catchup=False,
    tags=['data-ingestion', 'football-data', 'daily'],
) as dag_daily:
    
    task_ingest = PythonOperator(
        task_id='ingest_data',
        python_callable=run_data_ingestion,
        params={'task_type': 'full'},
        provide_context=True,
    )
    
    task_validate = PythonOperator(
        task_id='validate_quality',
        python_callable=validate_data_quality,
        provide_context=True,
    )
    
    task_notify = PythonOperator(
        task_id='send_notification',
        python_callable=send_summary_notification,
        provide_context=True,
    )
    
    # ä»»åŠ¡ä¾èµ–
    task_ingest >> task_validate >> task_notify


# ========================
# DAG 2: æ¯å°æ—¶å¢é‡æ›´æ–°
# ========================
with DAG(
    'football_data_hourly_incremental',
    default_args=default_args,
    description='æ¯å°æ—¶å¢é‡åŒæ­¥ Football Dataï¼ˆèµ›ä¸­æ›´æ–°ï¼‰',
    schedule_interval='0 * * * *',  # æ¯å°æ—¶
    start_date=days_ago(1),
    catchup=False,
    tags=['data-ingestion', 'football-data', 'hourly'],
) as dag_hourly:
    
    task_ingest_incremental = PythonOperator(
        task_id='ingest_data_incremental',
        python_callable=run_data_ingestion,
        params={'task_type': 'incremental'},
        provide_context=True,
    )
    
    task_validate_incremental = PythonOperator(
        task_id='validate_quality',
        python_callable=validate_data_quality,
        provide_context=True,
    )
    
    # ä»»åŠ¡ä¾èµ–
    task_ingest_incremental >> task_validate_incremental


# ========================
# DAG 3: æŒ‰éœ€æ‰‹åŠ¨è§¦å‘
# ========================
with DAG(
    'football_data_manual_trigger',
    default_args=default_args,
    description='æ‰‹åŠ¨è§¦å‘çš„æ•°æ®æ‘„å–ä»»åŠ¡',
    schedule_interval=None,  # æ— è‡ªåŠ¨è°ƒåº¦
    start_date=days_ago(1),
    catchup=False,
    tags=['data-ingestion', 'football-data', 'manual'],
) as dag_manual:
    
    task_manual = PythonOperator(
        task_id='manual_ingest',
        python_callable=run_data_ingestion,
        params={'task_type': 'full'},
        provide_context=True,
    )

